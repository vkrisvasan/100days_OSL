{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMd/WhsZQNyhYxf8XiVf+Ed",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vkrisvasan/100days_OSL/blob/main/10_OSL__Composio.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "-7ae16UQPOSn"
      },
      "outputs": [],
      "source": [
        "#You have used 0 out of 100 requests in free tier\n",
        "!pip install groq composio-langchain langchain-groq -q"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import getpass\n",
        "credential_names = [\"GROQ_API_KEY\"]\n",
        "for credential in credential_names:\n",
        "  if credential not in os.environ:\n",
        "    os.environ[credential]=getpass.getpass(\"Provide your...\" + credential)"
      ],
      "metadata": {
        "id": "uXMcOMI5QFZC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08ac865e-12d3-4bab-c090-9db2328a6d3a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Provide your...GROQ_API_KEY··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from groq import Groq\n",
        "import json\n",
        "\n",
        "groq = Groq(api_key=os.environ['GROQ_API_KEY'])\n",
        "client = groq\n",
        "MODEL = \"llama-3.1-70b-versatile\" #'llama3-groq-70b-8192-tool-use-preview'"
      ],
      "metadata": {
        "id": "FdgB4oPjryS7"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate(expression):\n",
        "    \"\"\"Evaluate a mathematical expression\"\"\"\n",
        "    try:\n",
        "        result = eval(expression)\n",
        "        return json.dumps({\"result\": result})\n",
        "    except:\n",
        "        return json.dumps({\"error\": \"Invalid expression\"})\n"
      ],
      "metadata": {
        "id": "4CJUP9lQr13G"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tools = [\n",
        "        {\n",
        "            \"type\": \"function\",\n",
        "            \"function\": {\n",
        "                \"name\": \"calculate\",\n",
        "                \"description\": \"Evaluate a mathematical expression\",\n",
        "                \"parameters\": {\n",
        "                    \"type\": \"object\",\n",
        "                    \"properties\": {\n",
        "                        \"expression\": {\n",
        "                            \"type\": \"string\",\n",
        "                            \"description\": \"The mathematical expression to evaluate\",\n",
        "                        }\n",
        "                    },\n",
        "                    \"required\": [\"expression\"],\n",
        "                },\n",
        "            },\n",
        "        }\n",
        "    ]"
      ],
      "metadata": {
        "id": "l5A8VcgJr5hV"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user_prompt = \"What is 25 * 4 + 10?\"\n",
        "messages=[\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": \"You are a calculator assistant. Use the calculate function to perform mathematical operations and provide the results.\"\n",
        "        },\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": user_prompt,\n",
        "        }\n",
        "    ]\n",
        "response = client.chat.completions.create(\n",
        "        model=MODEL,\n",
        "        messages=messages,\n",
        "        tools=tools,\n",
        "        tool_choice=\"auto\",\n",
        "        max_tokens=4096\n",
        "    )\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j8fb6mzrr8ks",
        "outputId": "c9a03112-4542-4f29-a390-d6e465cc28f2"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ChatCompletion(id='chatcmpl-09c9b2dc-7b5f-434d-9b9d-c1ab82d29022', choices=[Choice(finish_reason='tool_calls', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_bxyc', function=Function(arguments='{\"expression\": \"25 * 4 + 10\"}', name='calculate'), type='function')]))], created=1733970520, model='llama-3.1-70b-versatile', object='chat.completion', system_fingerprint='fp_b6828be2c9', usage=CompletionUsage(completion_tokens=20, prompt_tokens=244, total_tokens=264, completion_time=0.08, prompt_time=0.044969279, queue_time=2.954602831, total_time=0.124969279), x_groq={'id': 'req_01jewb4qs0eddabdjb3px06fnt'})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response_message = response.choices[0].message\n",
        "print(\"response message:\",response_message)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PP5r8Afms2PI",
        "outputId": "e89bbdec-a4f4-4874-d70a-b934b72c9a28"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "response message: ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_bxyc', function=Function(arguments='{\"expression\": \"25 * 4 + 10\"}', name='calculate'), type='function')])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain-groq -q\n",
        "from langchain_groq import ChatGroq  # Correct import for ChatGroq class\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain import LLMChain, PromptTemplate\n",
        "from langchain_groq.chat import ChatCompletionMessage, ChatCompletionMessageToolCall, Function\n",
        "# The chat functionalities might be provided by the 'langchain-groq' package.\n",
        "# Proceed with the rest of your code using the classes imported from 'langchain_groq.chat'.\n",
        "\n",
        "ChatCompletionMessage(content=None,\n",
        "                     role='assistant',\n",
        "                     function_call=None,\n",
        "                     tool_calls=[ChatCompletionMessageToolCall(id='call_59xh',\n",
        "                                 function=Function(arguments='{\"expression\": \"25 * 4 + 10\"}', name='calculate'), type='function')])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 536
        },
        "id": "LLMVYbjGs_I-",
        "outputId": "49d7afba-6448-45c2-a183-24d276d1db32"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'langchain_community'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-ce88e2de1cc4>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pip install langchain-groq -q'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain_groq\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mChatGroq\u001b[0m  \u001b[0;31m# Correct import for ChatGroq class\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchat_models\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mChatOpenAI\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLLMChain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPromptTemplate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain_groq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchat\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mChatCompletionMessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mChatCompletionMessageToolCall\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFunction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/chat_models/__init__.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m__getattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain_community\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mchat_models\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;31m# If not in interactive env, raise warning.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'langchain_community'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tool_calls = response_message.tool_calls\n",
        "if tool_calls:\n",
        "        available_functions = {\n",
        "            \"calculate\": calculate,\n",
        "        }\n",
        "        messages.append(response_message)\n",
        "        for tool_call in tool_calls:\n",
        "            function_name = tool_call.function.name\n",
        "            function_to_call = available_functions[function_name]\n",
        "            function_args = json.loads(tool_call.function.arguments)\n",
        "            function_response = function_to_call(\n",
        "                expression=function_args.get(\"expression\")\n",
        "            )\n",
        "            messages.append(\n",
        "                {\n",
        "                    \"tool_call_id\": tool_call.id,\n",
        "                    \"role\": \"tool\",\n",
        "                    \"name\": function_name,\n",
        "                    \"content\": function_response,\n",
        "                }\n",
        "            )\n",
        "        second_response = client.chat.completions.create(\n",
        "            model=MODEL,\n",
        "            messages=messages\n",
        "        )\n",
        "        print(second_response.choices[0].message.content)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JvRd8fDItG6Y",
        "outputId": "5b31bf87-1804-48d4-d7b8-51a36c5f5bd6"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "25 * 4 = 100\n",
            "100 + 10 = 110\n",
            "\n",
            "The result of 25 * 4 + 10 is 110.\n"
          ]
        }
      ]
    }
  ]
}